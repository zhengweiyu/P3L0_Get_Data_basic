{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3-L0:  数据提取基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习: 解析 CSV 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your task is to read the input DATAFILE line by line, and for the first 10 lines (not including the header)\n",
    "# split each line on \",\" and then for each line, create a dictionary\n",
    "# where the key is the header title of the field, and the value is the value of that field in the row.\n",
    "# The function parse_file should return a list of dictionaries,\n",
    "# each data line in the file being a single list entry.\n",
    "# Field names and values should not contain extra whitespace, like spaces or newline characters.\n",
    "# You can use the Python string method strip() to remove the extra whitespace.\n",
    "# You have to parse only the first 10 data lines in this exercise,\n",
    "# so the returned list should have 10 entries!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我的解法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"beatles-diskography.csv\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    data = []\n",
    "    with open(datafile, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if len(data) < 10:\n",
    "                data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讲师解法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"beatles-diskography.csv\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    data = []\n",
    "    with open(datafile, \"r\") as f:\n",
    "        header = f.readline().split(\",\")\n",
    "        counter = 0\n",
    "        for line in f:\n",
    "            if counter == 10:\n",
    "                break\n",
    "            fields = line.split(\",\")\n",
    "            entry = {}\n",
    "            \n",
    "            for i, value in enumerate(fields):\n",
    "                entry[header[i].strip()] = value.strip()\n",
    "            data.append(entry)\n",
    "            counter += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 用 strip() 函数清理字符串中的空格\n",
    "+ 用枚举 enumerate 取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # a simple test of your implemetation\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    d = parse_file(datafile)\n",
    "    firstline = {'Title': 'Please Please Me', 'UK Chart Position': '1', 'Label': 'Parlophone(UK)', 'Released': '22 March 1963', 'US Chart Position': '-', 'RIAA Certification': 'Platinum', 'BPI Certification': 'Gold'}\n",
    "    tenthline = {'Title': '', 'UK Chart Position': '1', 'Label': 'Parlophone(UK)', 'Released': '10 July 1964', 'US Chart Position': '-', 'RIAA Certification': '', 'BPI Certification': 'Gold'}\n",
    "\n",
    "    assert d[0] == firstline\n",
    "    assert d[9] == tenthline\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习: 读取 Excel 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Your task is as follows:\n",
    "- read the provided Excel file\n",
    "- find and return the min, max and average values for the COAST region\n",
    "- find and return the time value for the min and max entries\n",
    "- the time values should be returned as Python tuples\n",
    "\n",
    "Please see the test function for the expected return format\n",
    "\"\"\"\n",
    "\n",
    "import xlrd\n",
    "from zipfile import ZipFile\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我的解法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    ### example on how you can get the data\n",
    "    #sheet_data = [[sheet.cell_value(r, col) for col in range(sheet.ncols)] for r in range(sheet.nrows)]\n",
    "\n",
    "    ### other useful methods:\n",
    "    # print \"\\nROWS, COLUMNS, and CELLS:\"\n",
    "    # print \"Number of rows in the sheet:\", \n",
    "    # print sheet.nrows\n",
    "    # print \"Type of data in cell (row 3, col 2):\", \n",
    "    # print sheet.cell_type(3, 2)\n",
    "    # print \"Value in cell (row 3, col 2):\", \n",
    "    # print sheet.cell_value(3, 2)\n",
    "    # print \"Get a slice of values in column 3, from rows 1-3:\"\n",
    "    # print sheet.col_values(3, start_rowx=1, end_rowx=4)\n",
    "\n",
    "    # print \"\\nDATES:\"\n",
    "    # print \"Type of data in cell (row 1, col 0):\", \n",
    "    # print sheet.cell_type(1, 0)\n",
    "    # exceltime = sheet.cell_value(1, 0)\n",
    "    # print \"Time in Excel format:\",\n",
    "    # print exceltime\n",
    "    # print \"Convert time to a Python datetime tuple, from the Excel float:\",\n",
    "    # print xlrd.xldate_as_tuple(exceltime, 0)\n",
    "    \n",
    "    time_values = sheet.col_values(1, start_rowx=1)\n",
    "    maxvalue = max(time_values)\n",
    "    minvalue = min(time_values)\n",
    "    average = sum(time_values) / float(len(time_values))\n",
    "    \n",
    "    maxvalue_row = time_values.index(maxvalue) + 1\n",
    "    maxtime = xlrd.xldate_as_tuple(sheet.cell_value(maxvalue_row , 0), 0)\n",
    "    \n",
    "    minvalue_row = time_values.index(minvalue) + 1\n",
    "    mintime = xlrd.xldate_as_tuple(sheet.cell_value(minvalue_row , 0), 0)\n",
    "    \n",
    "    # print maxvalue\n",
    "    # print maxtime\n",
    "    # print minvalue\n",
    "    # print mintime\n",
    "    # print average\n",
    "    \n",
    "    data = {\n",
    "            'maxtime': maxtime,\n",
    "            'maxvalue': maxvalue,\n",
    "            'mintime': mintime,\n",
    "            'minvalue': minvalue,\n",
    "            'avgcoast': average\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "\n",
    "    assert data['maxtime'] == (2013, 8, 13, 17, 0, 0)\n",
    "    assert round(data['maxvalue'], 10) == round(18779.02551, 10)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习: JSON Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To experiment with this code freely you will have to run this code locally.\n",
    "# Take a look at the main() function for an example of how to use the code.\n",
    "# We have provided example json output in the other code editor tabs for you to\n",
    "# look at, but you will not be able to run any queries through our UI.\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "BASE_URL = \"http://musicbrainz.org/ws/2/\"\n",
    "ARTIST_URL = BASE_URL + \"artist/\"\n",
    "\n",
    "# query parameters are given to the requests.get function as a dictionary; this\n",
    "# variable contains some starter parameters.\n",
    "query_type = {  \"simple\": {},\n",
    "                \"atr\": {\"inc\": \"aliases+tags+ratings\"},\n",
    "                \"aliases\": {\"inc\": \"aliases\"},\n",
    "                \"releases\": {\"inc\": \"releases\"}}\n",
    "\n",
    "\n",
    "def query_site(url, params, uid=\"\", fmt=\"json\"):\n",
    "    # This is the main function for making queries to the musicbrainz API.\n",
    "    # A json document should be returned by the query.\n",
    "    params[\"fmt\"] = fmt\n",
    "    r = requests.get(url + uid, params=params)\n",
    "    print \"requesting\", r.url\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def query_by_name(url, params, name):\n",
    "    # This adds an artist name to the query parameters before making\n",
    "    # an API call to the function above.\n",
    "    params[\"query\"] = \"artist:\" + name\n",
    "    return query_site(url, params)\n",
    "\n",
    "\n",
    "def pretty_print(data, indent=4):\n",
    "    # After we get our output, we can format it to be more readable\n",
    "    # by using this function.\n",
    "    if type(data) == dict:\n",
    "        print json.dumps(data, indent=indent, sort_keys=True)\n",
    "    else:\n",
    "        print data\n",
    "\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    Modify the function calls and indexing below to answer the questions on\n",
    "    the next quiz. HINT: Note how the output we get from the site is a\n",
    "    multi-level JSON document, so try making print statements to step through\n",
    "    the structure one level at a time or copy the output to a separate output\n",
    "    file.\n",
    "    '''\n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Nirvana\")\n",
    "    pretty_print(results)\n",
    "\n",
    "    artist_id = results[\"artists\"][1][\"id\"]\n",
    "    print \"\\nARTIST:\"\n",
    "    pretty_print(results[\"artists\"][1])\n",
    "\n",
    "    artist_data = query_site(ARTIST_URL, query_type[\"releases\"], artist_id)\n",
    "    releases = artist_data[\"releases\"]\n",
    "    print \"\\nONE RELEASE:\"\n",
    "    pretty_print(releases[0], indent=2)\n",
    "    release_titles = [r[\"title\"] for r in releases]\n",
    "\n",
    "    print \"\\nALL TITLES:\"\n",
    "    for t in release_titles:\n",
    "        print t\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 有多少个名为First Aid Kit的乐队"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AFirst+Aid+Kit&fmt=json\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"First Aid Kit\")\n",
    "pretty_print(results[\"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 皇后乐队的发源地是哪里？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AQueen&fmt=json\n",
      "London\n",
      "Brooklyn\n"
     ]
    }
   ],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Queen\")\n",
    "i = 0\n",
    "loop = results[\"count\"]\n",
    "for i in range(loop):\n",
    "    try:\n",
    "        pretty_print(results[\"artists\"][i][\"begin-area\"][\"name\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 披头士的西班牙别名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AThe+Beatles&fmt=json\n",
      "[{u'name': u'\\ub354 \\ube44\\ud2c0\\uc988', u'locale': u'ko', u'end-date': None, u'primary': True, u'sort-name': u'\\ub354 \\ube44\\ud2c0\\uc988', u'type': None, u'begin-date': None}, {u'name': u'\\u30b6\\u30fb\\u30d3\\u30fc\\u30c8\\u30eb\\u30ba', u'locale': u'ja', u'end-date': None, u'primary': True, u'sort-name': u'\\u30d3\\u30fc\\u30c8\\u30eb\\u30ba (\\u30b6)', u'type': None, u'begin-date': None}, {u'name': u'B', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'B', u'type': u'Search hint', u'begin-date': None}, {u'name': u'Be', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'Be', u'type': u'Search hint', u'begin-date': None}, {u'name': u'Beat', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'Beat', u'type': u'Search hint', u'begin-date': None}, {u'name': u'Beatles', u'locale': u'en', u'end-date': None, u'primary': None, u'sort-name': u'Beatles', u'type': u'Artist name', u'begin-date': None}, {u'name': u'Beetles', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'Beetles', u'type': u'Search hint', u'begin-date': None}, {u'name': u'fab four', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'fab four', u'type': u'Search hint', u'begin-date': None}, {u'name': u'Los Beatles', u'locale': u'es', u'end-date': None, u'primary': True, u'sort-name': u'Los Beatles', u'type': None, u'begin-date': None}, {u'name': u'The Beatles', u'locale': u'en', u'end-date': None, u'primary': True, u'sort-name': u'Beatles, The', u'type': u'Artist name', u'begin-date': None}, {u'name': u'The Savage Young Beatles', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'Savage Young Beatles, The', u'type': None, u'begin-date': None}, {u'name': u'\\u0411\\u0438\\u0442\\u043b\\u0437', u'locale': u'ru', u'end-date': None, u'primary': True, u'sort-name': u'\\u0411\\u0438\\u0442\\u043b\\u0437', u'type': None, u'begin-date': None}, {u'name': u'\\u62ab\\u5934\\u58eb', u'locale': u'zh_Hans', u'end-date': None, u'primary': True, u'sort-name': u'\\u62ab\\u5934\\u58eb', u'type': None, u'begin-date': None}, {u'name': u'\\u62ab\\u982d\\u56db', u'locale': u'zh_Hant', u'end-date': None, u'primary': True, u'sort-name': u'\\u62ab\\u982d\\u56db', u'type': None, u'begin-date': None}]\n",
      "[{u'name': u'Tape-Beatles', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'Tape-Beatles', u'type': None, u'begin-date': None}]\n",
      "[{u'name': u'Beatles Revival Band', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'Beatles Revival Band', u'type': None, u'begin-date': None}]\n",
      "[{u'name': u'The Silver Beatles', u'locale': None, u'end-date': None, u'primary': None, u'sort-name': u'Silver Beatles, The', u'type': None, u'begin-date': None}]\n"
     ]
    }
   ],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"The Beatles\")\n",
    "i = 0\n",
    "loop = results[\"count\"]\n",
    "for i in range(loop):\n",
    "    try:\n",
    "        pretty_print(results[\"artists\"][i][\"aliases\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- “涅槃”的词义消歧方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AKurt+Cobain&fmt=json\n",
      "German post-punk/indie/art-rock band\n",
      "Japanese band\n",
      "UK Hardcore\n",
      "Probably Houston Rapper\n",
      "US rapper Miguel Blackmer-Hart\n"
     ]
    }
   ],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Kurt Cobain\")\n",
    "i = 0\n",
    "loop = results[\"count\"]\n",
    "for i in range(loop):\n",
    "    try:\n",
    "        pretty_print(results[\"artists\"][i][\"disambiguation\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One Direction 乐队是什么时候成立的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AOne+Direction&fmt=json\n",
      "English-Irish boy band formed in 2010\n",
      "San Francisco band\n",
      "New Zealand punk?\n",
      "USA punk band\n",
      "rock\n",
      "Hardcore/Gabber DJ Team\n",
      "Church choir at Lourdes\n"
     ]
    }
   ],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"One Direction\")\n",
    "i = 0\n",
    "loop = results[\"count\"]\n",
    "for i in range(loop):\n",
    "    try:\n",
    "        pretty_print(results[\"artists\"][i][\"disambiguation\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习: 使用 CSV 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYour task is to process the supplied file and use the csv module to extract data from it.\\nThe data comes from NREL (National Renewable Energy Laboratory) website. Each file\\ncontains information from one meteorological station, in particular - about amount of\\nsolar and wind energy for each hour of day.\\n\\nNote that the first line of the datafile is neither data entry, nor header. It is a line\\ndescribing the data source. You should extract the name of the station from it.\\n\\nThe data should be returned as a list of lists (not dictionaries).\\nYou can use the csv modules \"reader\" method to get data in such format.\\nAnother useful method is next() - to get the next line from the iterator.\\nYou should only change the parse_file function.\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Your task is to process the supplied file and use the csv module to extract data from it.\n",
    "The data comes from NREL (National Renewable Energy Laboratory) website. Each file\n",
    "contains information from one meteorological station, in particular - about amount of\n",
    "solar and wind energy for each hour of day.\n",
    "\n",
    "Note that the first line of the datafile is neither data entry, nor header. It is a line\n",
    "describing the data source. You should extract the name of the station from it.\n",
    "\n",
    "The data should be returned as a list of lists (not dictionaries).\n",
    "You can use the csv modules \"reader\" method to get data in such format.\n",
    "Another useful method is next() - to get the next line from the iterator.\n",
    "You should only change the parse_file function.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"745090.csv\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    name = \"\"\n",
    "    data = []\n",
    "    with open(datafile,'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        row_num = 0\n",
    "        for row in reader:\n",
    "            if row_num == 0:\n",
    "                name = row[1]\n",
    "            elif row_num >= 2:    \n",
    "                data.append(row)\n",
    "            row_num +=1\n",
    "    # print name\n",
    "    # print data[0][1]\n",
    "    # print data[2][0]\n",
    "    # print data[2][5]\n",
    "    # Do not change the line below\n",
    "    return (name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    name, data = parse_file(datafile)\n",
    "\n",
    "    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\n",
    "    assert data[0][1] == \"01:00\"\n",
    "    assert data[2][0] == \"01/01/2005\"\n",
    "    assert data[2][5] == \"2\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 练习: Excel 至 CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Find the time and value of max load for each of the regions\n",
    "COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character | as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file.\n",
    "'''\n",
    "\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    data = []\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(9):\n",
    "        if i >= 1:\n",
    "            station = sheet.cell_value(0, i)\n",
    "\n",
    "            time_values = sheet.col_values(i, start_rowx=1)\n",
    "            maxvalue = max(time_values)\n",
    "\n",
    "            maxvalue_row = time_values.index(maxvalue) + 1\n",
    "            maxtime = xlrd.xldate_as_tuple(sheet.cell_value(maxvalue_row , 0), 0)\n",
    "            \n",
    "            data_row = [station,maxtime[0],maxtime[1],maxtime[2],maxtime[3],maxvalue]\n",
    "            \n",
    "            data.append(data_row)\n",
    "    # Remember that you can use xlrd.xldate_as_tuple(sometime, 0) to convert\n",
    "    # Excel date to Python tuple of (year, month, day, hour, minute, second)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_file(data, filename):\n",
    "    # YOUR CODE HERE\n",
    "    with open(filename, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter='|')\n",
    "        writer.writerow(['Station','Year','Month','Day','Hour','Max Load'])\n",
    "        for i in range(len(data)):\n",
    "            writer.writerow([data[i][0],data[i][1],data[i][2],data[i][3],data[i][4],data[i][5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "    save_file(data, outfile)\n",
    "\n",
    "    number_of_rows = 0\n",
    "    stations = []\n",
    "\n",
    "    ans = {'FAR_WEST': {'Max Load': '2281.2722140000024',\n",
    "                        'Year': '2013',\n",
    "                        'Month': '6',\n",
    "                        'Day': '26',\n",
    "                        'Hour': '17'}}\n",
    "    correct_stations = ['COAST', 'EAST', 'FAR_WEST', 'NORTH',\n",
    "                        'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n",
    "    fields = ['Year', 'Month', 'Day', 'Hour', 'Max Load']\n",
    "\n",
    "    with open(outfile) as of:\n",
    "        csvfile = csv.DictReader(of, delimiter=\"|\")\n",
    "        for line in csvfile:\n",
    "            station = line['Station']\n",
    "            if station == 'FAR_WEST':\n",
    "                for field in fields:\n",
    "                    # Check if 'Max Load' is within .1 of answer\n",
    "                    if field == 'Max Load':\n",
    "                        max_answer = round(float(ans[station][field]), 1)\n",
    "                        max_line = round(float(line[field]), 1)\n",
    "                        assert max_answer == max_line\n",
    "\n",
    "                    # Otherwise check for equality\n",
    "                    else:\n",
    "                        assert ans[station][field] == line[field]\n",
    "\n",
    "            number_of_rows += 1\n",
    "            stations.append(station)\n",
    "\n",
    "        # Output should be 8 lines not including header\n",
    "        assert number_of_rows == 8\n",
    "\n",
    "        # Check Station Names\n",
    "        assert set(stations) == set(correct_stations)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2env]",
   "language": "python",
   "name": "conda-env-py2env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
